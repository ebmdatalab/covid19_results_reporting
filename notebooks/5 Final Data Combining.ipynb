{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent = str(Path(cwd).parents[0])\n",
    "sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(parent + '/data/cleaned_ictrp_29June2020.csv').drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_registration'] = pd.to_datetime(df['date_registration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_check(df, fields):\n",
    "    check = df[fields].groupby(fields[0], as_index=False).count().sort_values(by='source_register', ascending=False)\n",
    "    return check[check.source_register > 1]\n",
    "\n",
    "dedupe_check(df, ['trialid', 'source_register'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclusion logic\n",
    "\n",
    "int_prev = ((df.study_type == 'Interventional') | (df.study_type == 'Prevention'))\n",
    "\n",
    "in_2020 = (df.date_registration >= pd.Timestamp(2020,1,1))\n",
    "\n",
    "#At the moment, this deals with withdrawn trials from the ChiCTR. Data from other registries doesn't\n",
    "#Reliable make it to the ICTRP. We will exclude withdrawn trials from ClinicalTrials.gov\n",
    "#When we join that in below.\n",
    "withdrawn = ~((df.public_title.str.contains('Cancelled')) | df.public_title.str.contains('Retracted due to'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['included'] = np.where(int_prev & in_2020 & withdrawn, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_data = pd.read_csv(parent + '/data/registry_data/registry_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only what we need to join\n",
    "reg_cols = ['trial_id', 'trial_status', 'pcd', 'scd', 'relevant_comp_date', 'tabular_results', \n",
    "            'potential_other_results']\n",
    "\n",
    "\n",
    "df_reg_merge = df.merge(registry_data[reg_cols], how='left', left_on='trialid', \n",
    "                        right_on='trial_id').drop('trial_id', axis=1)\n",
    "\n",
    "df_reg_merge['tabular_results'] = df_reg_merge['tabular_results'].fillna(0).astype(int)\n",
    "df_reg_merge['potential_other_results'] = df_reg_merge['potential_other_results'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluding more withdrawn trials\n",
    "\n",
    "df_reg_merge['included'] = np.where((df_reg_merge.trial_status == 'Withdrawn'), 0, df_reg_merge['included'])\n",
    "df_reg_merge = df_reg_merge.drop('trial_status', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe_check(df_reg_merge, ['trialid', 'source_register'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_hits = pd.read_csv(parent + '/data/screening_hit_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "We have to change EUCTR2020-000890-25 to \"EUCTR2020-000890-25-FR\" and \"EUCTR2020-001934-37\" to \"EUCTR2020-001934-37-ES\" to match how they appear in the ICTRP for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_hits['trn_1'] = auto_hits['trn_1'].str.replace('EUCTR2020-000890-25', 'EUCTR2020-000890-25-FR').str.replace('EUCTR2020-001934-37', 'EUCTR2020-001934-37-ES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we remove the record PMID32339248 as this was a duplicate PubMed entry to 32330277. \n",
    "#We contacted PubMed and this has now been deleted from PubMed entirely.\n",
    "\n",
    "auto_hits = auto_hits[auto_hits.id != '32339248'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_rules(grp):\n",
    "    l = []\n",
    "    for x in grp:\n",
    "        if x in l:\n",
    "            pass\n",
    "        else:\n",
    "            l.append(x)\n",
    "    if len(l) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return l\n",
    "\n",
    "def max_list_size(column):\n",
    "    max_size = 0\n",
    "    for x in column:\n",
    "        if len(x) > max_size:\n",
    "            max_size = len(x)\n",
    "    return max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_auto = auto_hits.groupby('trn_1', as_index=False).agg(group_rules)\n",
    "\n",
    "filtered = group_auto[['trn_1', 'trn_2', 'id', 'doi', 'results_pub_type',  \n",
    "                       'completion_date', 'publication_date']].reset_index(drop=True)\n",
    "\n",
    "rename = ['hit_tid', 'hit_tid2', 'auto_id', 'doi', 'results_pub_type', 'pub_completion_date', 'publication_date']\n",
    "\n",
    "filtered.columns = rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in rename[2:]:\n",
    "    col_list = filtered[name].tolist()\n",
    "    max_size = max_list_size(col_list)\n",
    "    cols = [(name + '_{}').format(x) for x in range(1, max_size+1)]\n",
    "    filtered[cols] = pd.DataFrame(col_list, index=filtered.index)\n",
    "    filtered = filtered.drop(name, axis=1)\n",
    "\n",
    "#Fixing this\n",
    "filtered['hit_tid2'] = filtered['hit_tid2'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_reg_merge.merge(filtered, how='left', left_on='trialid', right_on='hit_tid').drop('hit_tid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe_check(df_final, ['trialid', 'source_register'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for trials that are in our results but not in the ICTRP dataset\n",
    "\n",
    "a = df_reg_merge.trialid.tolist()\n",
    "b = filtered.hit_tid.tolist()\n",
    "\n",
    "set(b) - set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['relevant_comp_date'] = pd.to_datetime(df_final['relevant_comp_date'])\n",
    "\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditions for round inclusion:\n",
    "\n",
    "overall_inclusion = (df_final.included == 1)\n",
    "date_inclusion = (df_final.relevant_comp_date < pd.Timestamp(2020,7,1))\n",
    "reg_or_pub = ((df_final.results_pub_type_1.notnull()) | (df_final.tabular_results == 1) | (df_final.potential_other_results == 1))\n",
    "\n",
    "\n",
    "df_final[\"round_inclusion\"] = np.where((overall_inclusion & (date_inclusion | reg_or_pub)),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.round_inclusion.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(parent + '/data/final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
