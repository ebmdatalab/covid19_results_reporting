{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the raw ICTRP COVID-19 registered trials CSV, cuts it down to only the fields we need, and cleans/processes the data using techniques developed for covid19.trialstracker.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent = str(Path(cwd).parents[0])\n",
    "sys.path.append(parent)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(parent + '/data/ictrp_data/COVID19-web_29June2020.csv', dtype={'Phase': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data_cleaning import enrollment_dates, fix_date, fix_errors, d_c\n",
    "\n",
    "#This is fixes for known broken enrollement dates    \n",
    "known_errors= {\n",
    "    'IRCT20200310046736N1': ['2641-06-14', '2020-04-01'],\n",
    "    'EUCTR2020-001909-22-FR': ['nan', '2020-04-29']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fix_errors(known_errors, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date enrollement'] = df['Date enrollement'].apply(enrollment_dates)\n",
    "\n",
    "df['Date registration'] = pd.to_datetime(df['Date registration3'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data_cleaning import enroll_extract\n",
    "\n",
    "#Extracting target enrollment\n",
    "size = df['Target size'].tolist()\n",
    "\n",
    "df['target_enrollment'] = enroll_extract(size)\n",
    "\n",
    "#Creating retrospective registration\n",
    "df['retrospective_registration'] = np.where(df['Date registration'] > df['Date enrollement'], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only what we need right now\n",
    "\n",
    "cols = ['TrialID', 'Source Register', 'Date registration', 'Date enrollement', 'retrospective_registration', \n",
    "        'Primary sponsor', 'Recruitment Status', 'Phase', 'Study type', 'Countries', 'Public title', \n",
    "        'Intervention', 'target_enrollment', 'web address', 'results yes no', 'results url link']\n",
    "\n",
    "df_cond = df[cols].reset_index(drop=True)\n",
    "\n",
    "#renaming columns to match old format so I don't have to change them throughout\n",
    "df_cond.columns = ['TrialID', 'Source_Register', 'Date_registration', 'Date_enrollement', \n",
    "                   'retrospective_registration', 'Primary_sponsor', 'Recruitment_Status', 'Phase', 'Study_type', \n",
    "                   'Countries', 'Public_title', 'Intervention', 'target_enrollment', 'web_address', \n",
    "                   'has_results', 'results_url_link']\n",
    "\n",
    "print(f'The ICTRP shows {len(df_cond)} trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data = parent + '/data/manual_data_for_covid_project.xlsx'\n",
    "\n",
    "c_reg = pd.read_excel(manual_data, sheet_name = 'cross registrations')\n",
    "replace_ids = c_reg.id_to_replace.tolist()\n",
    "\n",
    "replaced = df_cond[df_cond.TrialID.isin(replace_ids)]\n",
    "print(f'{len(replaced)} known cross registrations will be assessed')\n",
    "\n",
    "df_cond_nc = df_cond[~(df_cond.TrialID.isin(replace_ids))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-adding trials as cross-registrations\n",
    "\n",
    "additions = pd.read_excel(manual_data, sheet_name = 'additional_trials').drop('from', \n",
    "                                                                                     axis=1).reset_index(drop=True)\n",
    "\n",
    "print(f'An additional {len(additions)} known preferred cross registrations were added to the data')\n",
    "\n",
    "df_cond_all = df_cond_nc.append(additions)\n",
    "df_cond_all['Date_enrollement'] = df_cond_all['Date_enrollement'].apply(fix_date)\n",
    "\n",
    "print(f'The final dataset is {len(df_cond_all)} trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This ensures our check for retrospective registration is accurate w/r/t cross-registrations\n",
    "\n",
    "c_r_comp_dates = c_reg[['trial_id_keep', 'cross_reg_date']].groupby('trial_id_keep', as_index=False).min()\n",
    "c_r_merged = c_r_comp_dates.merge(df_cond_nc[['TrialID', 'Date_registration', 'Date_enrollement']], \n",
    "                                 left_on='trial_id_keep', right_on='TrialID', how='left')\n",
    "c_r_merged['earliest_reg'] = c_r_merged[['cross_reg_date', 'Date_registration']].min(axis=1)\n",
    "pre_reg = c_r_merged[c_r_merged.TrialID.notnull() & (c_r_merged.earliest_reg <= c_r_merged.Date_enrollement)].trial_id_keep.to_list()\n",
    "\n",
    "ret_reg = c_r_merged[c_r_merged.TrialID.notnull() & ~(c_r_merged.earliest_reg <= c_r_merged.Date_enrollement)].trial_id_keep.to_list()\n",
    "ret_reg\n",
    "\n",
    "for index, row in df_cond_all.iterrows():\n",
    "    if row.TrialID in pre_reg:\n",
    "        df_cond_all.at[index, 'retrospective_registration'] = True\n",
    "    elif row.TrialID in ret_reg:\n",
    "        df_cond_all.at[index, 'retrospective_registration'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally, add cross-registration field\n",
    "\n",
    "df_cond_all = df_cond_all.merge(c_reg[['trial_id_keep', 'additional_ids']].drop_duplicates(), \n",
    "                              left_on='TrialID', \n",
    "                              right_on='trial_id_keep', \n",
    "                              how='left').drop('trial_id_keep', axis=1).rename(columns=\n",
    "                                                                               {'additional_ids':\n",
    "                                                                                'cross_registrations'}\n",
    "                                                                              ).reset_index(drop=True)\n",
    "\n",
    "df_cond_all['cross_registrations'] = df_cond_all['cross_registrations'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning various fields. \n",
    "#One important thing we have to do is make sure there are no nulls or else the data won't properly load onto the website\n",
    "\n",
    "#semi-colons in the intervention field mess with CSV\n",
    "df_cond_all['Intervention'] = df_cond_all['Intervention'].str.replace(';', '')\n",
    "\n",
    "#Study Type\n",
    "obv_replace = ['Observational [Patient Registry]', 'observational', 'Observational Study']\n",
    "int_replace = ['interventional', 'Interventional clinical trial of medicinal product', 'Treatment', \n",
    "               'INTERVENTIONAL', 'Intervention', 'Interventional Study', 'PMS']\n",
    "hs_replace = ['Health services reaserch', 'Health Services reaserch', 'Health Services Research']\n",
    "\n",
    "df_cond_all['Study_type'] = (df_cond_all['Study_type'].str.replace(' study', '')\n",
    "                             .replace(obv_replace, 'Observational').replace(int_replace, 'Interventional')\n",
    "                             .replace('Epidemilogical research', 'Epidemiological research')\n",
    "                             .replace(hs_replace, 'Health services research')\n",
    "                             .replace('Others,meta-analysis etc', 'Other'))\n",
    "\n",
    "#phase\n",
    "df_cond_all['Phase'] = df_cond_all['Phase'].fillna('Not Applicable')\n",
    "na = ['0', 'Retrospective study', 'Not applicable', 'New Treatment Measure Clinical Study', 'Not selected', \n",
    "      'Phase 0', 'Diagnostic New Technique Clincal Study', '0 (exploratory trials)', 'Not Specified']\n",
    "p1 = ['1', 'Early Phase 1', 'I', 'Phase-1', 'Phase I']\n",
    "p12 = ['1-2', '2020-02-01 00:00:00', 'Phase I/II', 'Phase 1 / Phase 2', 'Phase 1/ Phase 2',\n",
    "       'Human pharmacology (Phase I): yes\\nTherapeutic exploratory (Phase II): yes\\nTherapeutic confirmatory - (Phase III): no\\nTherapeutic use (Phase IV): no\\n']\n",
    "p2 = ['2', 'II', 'Phase II', 'IIb', 'Phase-2', 'Phase2',\n",
    "      'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): yes\\nTherapeutic confirmatory - (Phase III): no\\nTherapeutic use (Phase IV): no\\n']\n",
    "p23 = ['Phase II/III', '2020-03-02 00:00:00', 'II-III', 'Phase 2 / Phase 3', 'Phase 2/ Phase 3', '2-3',\n",
    "       'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): yes\\nTherapeutic confirmatory - (Phase III): yes\\nTherapeutic use (Phase IV): no\\n']\n",
    "p3 = ['3', 'Phase III', 'Phase-3', 'III',\n",
    "      'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): no\\nTherapeutic confirmatory - (Phase III): yes\\nTherapeutic use (Phase IV): no\\n']\n",
    "p34 = ['Phase 3/ Phase 4', 'Phase III/IV',\n",
    "       'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): no\\nTherapeutic confirmatory - (Phase III): yes\\nTherapeutic use (Phase IV): yes\\n']\n",
    "p4 = ['4', 'IV', 'Post Marketing Surveillance', 'Phase IV', 'PMS',\n",
    "      'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): no\\nTherapeutic confirmatory - (Phase III): no\\nTherapeutic use (Phase IV): yes\\n']\n",
    "\n",
    "df_cond_all['Phase'] = (df_cond_all['Phase'].replace(na, 'Not Applicable').replace(p1, 'Phase 1')\n",
    "                        .replace(p12, 'Phase 1/Phase 2').replace(p2, 'Phase 2')\n",
    "                        .replace(p23, 'Phase 2/Phase 3').replace(p3, 'Phase 3').replace(p34, 'Phase 3/Phase 4')\n",
    "                        .replace(p4, 'Phase 4'))\n",
    "\n",
    "#Fixing Observational studies incorrectly given a Phase in ICTRP data\n",
    "m = ((df_cond_all.Phase.str.contains('Phase')) & (df_cond_all.Study_type == 'Observational'))\n",
    "df_cond_all['Phase'] = df_cond_all.Phase.where(~m, 'Not Applicable')\n",
    "\n",
    "#Recruitment Status\n",
    "df_cond_all['Recruitment_Status'] = df_cond_all['Recruitment_Status'].replace('Not recruiting', 'Not Recruiting')\n",
    "df_cond_all['Recruitment_Status'] = df_cond_all['Recruitment_Status'].fillna('No Status Given')\n",
    "\n",
    "#Get rid of messy accents\n",
    "from lib.data_cleaning import norm_names\n",
    "    \n",
    "df_cond_all['Primary_sponsor'] = df_cond_all.Primary_sponsor.apply(norm_names)\n",
    "df_cond_all['Primary_sponsor'] = df_cond_all['Primary_sponsor'].replace('NA', 'No Sponsor Name Given')\n",
    "df_cond_all['Primary_sponsor'] = df_cond_all['Primary_sponsor'].replace('nan', 'No Sponsor Name Given')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countries\n",
    "df_cond_all['Countries'] = df_cond_all['Countries'].fillna('No Country Given').replace('??', 'No Country Given')\n",
    "\n",
    "china_corr = ['Chian', 'China?', 'Chinese', 'Wuhan', 'Chinaese', 'china', 'Taiwan, Province Of China', \n",
    "              \"The People's Republic of China\"]\n",
    "\n",
    "country_values = df_cond_all['Countries'].tolist()\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for c in country_values:\n",
    "    country_list = []\n",
    "    if isinstance(c, float):\n",
    "        country_list.append('No Sponsor Name Given')\n",
    "    elif c == 'No Sponsor Name Given':\n",
    "        country_list.append('No Sponsor Name Given')\n",
    "    elif c in china_corr:\n",
    "        country_list.append('China')\n",
    "    elif c in ['Iran (Islamic Republic of)', 'Iran, Islamic Republic of']:\n",
    "        country_list.append('Iran')\n",
    "    elif c in ['Viet nam', 'Viet Nam']:\n",
    "        country_list.append('Vietnam')\n",
    "    elif c in ['Korea, Republic of', 'Korea, Republic Of', 'KOREA'] :\n",
    "        country_list.append('South Korea')\n",
    "    elif c in ['USA', 'United States of America', 'U.S.']:\n",
    "        country_list.append('United States')\n",
    "    elif c == 'Japan,Asia(except Japan),Australia,Europe':\n",
    "        country_list = ['Japan', 'Australia', 'Asia', 'Europe']\n",
    "    elif c == 'Japan,Asia(except Japan),North America,South America,Australia,Europe,Africa':\n",
    "        country_list = ['Japan, Asia(except Japan), North America, South America, Australia, Europe, Africa']\n",
    "    elif c == 'The Netherlands':\n",
    "        country_list.append('Netherlands')\n",
    "    elif c == 'England':\n",
    "        country_list.append('United Kingdom')\n",
    "    elif c == 'Japan,North America':\n",
    "        country_list = ['Japan', 'North America']\n",
    "    elif c == 'Czechia':\n",
    "        country_list.append('Czech Republic')\n",
    "    elif c == 'ASIA':\n",
    "        country_list.append('Asia')\n",
    "    elif c == 'EUROPE':\n",
    "        country_list.append('Europe')\n",
    "    elif c == 'MALAYSIA':\n",
    "        country_list.append('Malaysia')\n",
    "    elif c in ['Congo', 'Congo, Democratic Republic', 'Congo, The Democratic Republic of the']:\n",
    "        country_list.append('Democratic Republic of Congo')\n",
    "    elif c in [\"C√¥te D'Ivoire\", 'Cote Divoire']:\n",
    "        country_list.append(\"Cote d'Ivoire\")\n",
    "    elif ';' in c:\n",
    "        c_list = c.split(';')\n",
    "        unique_values = list(set(c_list))\n",
    "        for v in unique_values:\n",
    "            if v in china_corr:\n",
    "                country_list.append('China')\n",
    "            elif v in ['Iran (Islamic Republic of)', 'Iran, Islamic Republic of']:\n",
    "                country_list.append('Iran')\n",
    "            elif v in ['Korea, Republic of', 'Korea, Republic Of', 'KOREA']:\n",
    "                country_list.append('South Korea')\n",
    "            elif v in ['Viet nam', 'Viet Nam']:\n",
    "                country_list.append('Vietnam')\n",
    "            elif v in ['USA', 'United States of America']:\n",
    "                country_list.append('United States')\n",
    "            elif v == 'The Netherlands':\n",
    "                country_list.append('Netherlands')\n",
    "            elif v == 'England':\n",
    "                country_list.append('United Kingdom')\n",
    "            elif v == 'Czechia':\n",
    "                country_list.append('Czech Republic')\n",
    "            elif v == 'ASIA':\n",
    "                country_list.append('Asia')\n",
    "            elif v == 'EUROPE':\n",
    "                country_list.append('Europe')\n",
    "            elif v == 'MALAYSIA':\n",
    "                country_list.append('Malaysia')\n",
    "            elif v in ['Congo', 'Congo, Democratic Republic', 'Congo, The Democratic Republic of the']:\n",
    "                country_list.append('Democratic Republic of Congo')\n",
    "            elif v in [\"C√¥te D'Ivoire\", 'Cote Divoire']:\n",
    "                country_list.append(\"Cote d'Ivoire\")\n",
    "            else:\n",
    "                country_list.append(v)\n",
    "    else:\n",
    "        country_list.append(c.strip())\n",
    "    new_list.append(', '.join(country_list))\n",
    "\n",
    "df_cond_all['Countries'] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing sponsor names\n",
    "#Run this cell, updating the spon_norm csv you are loading after manual adjusting\n",
    "#until you get the 'All sponsor names normalized' to print\n",
    "\n",
    "spon_norm = pd.read_excel(manual_data, sheet_name = 'sponsor')\n",
    "\n",
    "df_cond_norm = df_cond_all.merge(spon_norm, left_on = 'Primary_sponsor', right_on ='unique_spon_names', how='left')\n",
    "df_cond_norm = df_cond_norm.drop('unique_spon_names', axis=1)\n",
    "\n",
    "new_unique_spon_names = (df_cond_norm[df_cond_norm['normed_spon_names'].isna()][['Primary_sponsor', 'TrialID']]\n",
    "                        .groupby('Primary_sponsor').count())\n",
    "\n",
    "if len(new_unique_spon_names) > 0:\n",
    "    new_unique_spon_names.to_csv('to_norm.csv')\n",
    "    print('Update the normalisation schedule and rerun')\n",
    "else:\n",
    "    print('All sponsor names normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrating intervention type data\n",
    "#Once again, run to bring in the old int-type data, islolate the new ones, update, and rerun until\n",
    "#producing the all-clear message\n",
    "\n",
    "int_type = pd.read_excel(manual_data, sheet_name = 'intervention')\n",
    "df_cond_int = df_cond_norm.merge(int_type[['trial_id', 'study_category',\n",
    "                                           'intervention', 'intervention_list']], \n",
    "                                 left_on = 'TrialID', right_on = 'trial_id', how='left')\n",
    "\n",
    "df_cond_int = df_cond_int.drop('trial_id', axis=1)\n",
    "\n",
    "new_int_trials = df_cond_int[(df_cond_int['study_category'].isna()) | (df_cond_int['intervention'].isna())]\n",
    "\n",
    "if len(new_int_trials) > 0:\n",
    "    new_int_trials[['TrialID', 'Public_title', 'Intervention', 'study_category', \n",
    "                    'intervention', 'intervention_list']].to_csv('int_to_assess.csv')\n",
    "    print('Update the intervention type assessments and rerun')\n",
    "else:\n",
    "    print('All intervention types matched')\n",
    "    df_cond_int = df_cond_int.drop('Intervention', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final organising\n",
    "\n",
    "col_names = []\n",
    "\n",
    "for col in list(df_cond_int.columns):\n",
    "    col_names.append(col.lower())\n",
    "    \n",
    "df_cond_int.columns = col_names\n",
    "\n",
    "reorder = ['trialid', 'source_register', 'date_registration', 'date_enrollement', 'retrospective_registration', \n",
    "           'normed_spon_names', 'recruitment_status', 'phase', 'study_type', 'countries', 'public_title', \n",
    "           'study_category', 'intervention', 'intervention_list', 'target_enrollment', 'web_address', 'cross_registrations']\n",
    "\n",
    "df_final = df_cond_int[reorder].reset_index(drop=True).drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(parent + '/data/cleaned_ictrp_29June2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "encoding": "# -*- coding: utf-8 -*-",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
